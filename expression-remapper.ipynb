{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c112353",
   "metadata": {},
   "source": [
    "# Expression remapper\n",
    "\n",
    "This notebook is a simple app that allows users to map different facial expressions and motions to keyboard inputs. I aim to use this to play a video game like Dark Souls as a test.\n",
    "\n",
    "Using MediaPipe, and following their [face landmark detection guide](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cfc7d3",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51755a",
   "metadata": {},
   "source": [
    "#### Mediapipe\n",
    "Using for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe\n",
    "# opencv as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4dae5",
   "metadata": {},
   "source": [
    "#### PyAutoGUI\n",
    "Allows us to simulate keyboard events through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c45e16a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogui in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (0.9.54)\n",
      "Requirement already satisfied: pymsgbox in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pytweening>=1.0.4 in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyautogui) (1.0.7)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyautogui) (0.1.29)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: mouseinfo in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pyrect in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyscreenshot in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (3.1)\n",
      "Requirement already satisfied: Pillow>=9.2.0 in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (10.0.1)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from mouseinfo->pyautogui) (1.8.2)\n",
      "Requirement already satisfied: EasyProcess in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyscreenshot->pyscreeze>=0.1.21->pyautogui) (1.1)\n",
      "Requirement already satisfied: entrypoint2 in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyscreenshot->pyscreeze>=0.1.21->pyautogui) (1.1)\n",
      "Requirement already satisfied: mss in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pyscreenshot->pyscreeze>=0.1.21->pyautogui) (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e098e9",
   "metadata": {},
   "source": [
    "### Virtual Gamepad\n",
    "Allows us to emulate virtual game controller inputs.\n",
    "\n",
    "NOTE: it will install a driver that is needed. It also is only known to be stable on Windows, and it says 'experimental' for Linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b57f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vgamepad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70823c",
   "metadata": {},
   "source": [
    "### Pynput\n",
    "Allows us to emulate keyboard inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d92d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynput\n",
      "  Downloading pynput-1.7.6-py2.py3-none-any.whl (89 kB)\n",
      "     ---------------------------------------- 0.0/89.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 89.2/89.2 kB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pynput) (1.16.0)\n",
      "Installing collected packages: pynput\n",
      "Successfully installed pynput-1.7.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pynput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7024d4f",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7138d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe for face landmark detection\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# OpenCV for drawing utilities and webcam input\n",
    "import cv2\n",
    "\n",
    "# Generally useful for math\n",
    "import math\n",
    "\n",
    "# PyAutoGUI for simulating keyboard inputs\n",
    "from pyautogui import press, typewrite, hotkey # only really need 'press'\n",
    "\n",
    "# Pynput for simulating keyboard inputs\n",
    "from pynput.keyboard import Key, Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d315ea",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e59bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/face_landmarker.task'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae2b37",
   "metadata": {},
   "source": [
    "## Utility functions for extracting head orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3306f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!! import math\n",
    "\n",
    "# Toggles whether the remapping is currently active. If paused, no keypresses will be simulated.\n",
    "remapping_paused = True\n",
    "\n",
    "# State variables\n",
    "keyboard = Controller()\n",
    "moving_up = False\n",
    "moving_down = False\n",
    "moving_left = False\n",
    "moving_right = False\n",
    "\n",
    "# Real yaw pitch and roll\n",
    "yaw = 0.0 # Rotate left/right\n",
    "pitch = 0.0 # Tilt up/down\n",
    "roll = 0.0 # Tilt left/right\n",
    "\n",
    "# Calibrated yaw pitch and roll values\n",
    "calib_yaw = 0\n",
    "calib_pitch = 0\n",
    "calib_roll = 0\n",
    "\n",
    "# The rest positions, used to calculate the calibrated values\n",
    "rest_yaw = 0.0\n",
    "rest_pitch = 0.0\n",
    "rest_roll = 0.0\n",
    "\n",
    "# Extract the yaw, pitch, and roll of the head from the facial transformation matrix\n",
    "# (yaw, pitch, and roll are easier for me to work with than a matrix)\n",
    "def update_yaw_pitch_roll(mtrix):\n",
    "    # Get access to the global variables\n",
    "    global yaw\n",
    "    global pitch\n",
    "    global roll\n",
    "\n",
    "    # Calculate the yaw pitch and roll from the transformation matrix (conversion)\n",
    "    if mtrix[0][0] == 1.0:\n",
    "        yaw = math.atan2(mtrix[0][2], mtrix[2][3])\n",
    "        pitch = 0\n",
    "        roll = 0\n",
    "\n",
    "    elif mtrix[0][0] == -1.0:\n",
    "        yaw = math.atan2(mtrix[0][0], mtrix[2][3])\n",
    "        pitch = 0\n",
    "        roll = 0\n",
    "\n",
    "    else:\n",
    "        yaw = math.atan2(-mtrix[2][0], mtrix[0][0])\n",
    "        pitch = math.atan2(-mtrix[1][2], mtrix[1][1])\n",
    "        roll = math.asin(mtrix[1][0])\n",
    "\n",
    "    # Calculate the CALIBRATED yaw pitch roll values\n",
    "    global calib_yaw\n",
    "    global calib_pitch\n",
    "    global calib_roll\n",
    "    calib_yaw = yaw - rest_yaw\n",
    "    calib_pitch = pitch - rest_pitch\n",
    "    calib_roll = roll - rest_roll\n",
    "    \n",
    "#     # Yaw (look left/right)\n",
    "#     print(\"yaw is: {}\".format(math.degrees(calib_yaw)))\n",
    "#     if calib_yaw > 0:\n",
    "#         print(\"looking left\")\n",
    "#     elif calib_yaw < 0:\n",
    "#         print(\"looking right\")\n",
    "\n",
    "#         # Pitch (look up/down)\n",
    "#         print(\"pitch is: {}\".format(math.degrees(calib_pitch)))\n",
    "#         if calib_pitch > 0:\n",
    "#             print(\"looking down\")\n",
    "#         elif calib_pitch < 0:\n",
    "#             print(\"looking up\")\n",
    "\n",
    "#         # Roll (rilt left/right)\n",
    "#         print(\"roll is: {}\".format(math.degrees(calib_roll)))\n",
    "#         if calib_roll > 0:\n",
    "#             print(\"looking rolled right\")\n",
    "#         elif calib_roll < 0:\n",
    "#             print(\"looking rolled left\")\n",
    "\n",
    "    if not remapping_paused:\n",
    "        global moving_left\n",
    "        global moving_right\n",
    "        global moving_up\n",
    "        global moving_down\n",
    "        \n",
    "        #print(math.degrees(calib_pitch))\n",
    "        thresh = 10.0\n",
    "#         # Look Left / Right\n",
    "#         if math.degrees(calib_yaw) > thresh: # Head is facing left\n",
    "#             keyboard.release('d')\n",
    "#             moving_right = False\n",
    "#             if not moving_left:\n",
    "#                 keyboard.press('a')\n",
    "#                 moving_left = True\n",
    "#         elif math.degrees(calib_yaw) < -thresh: # Head is facing right\n",
    "#             keyboard.release('a')\n",
    "#             moving_left = False\n",
    "#             if not moving_right:\n",
    "#                 keyboard.press('d')\n",
    "#                 moving_right = True\n",
    "#         else: # Head is in neutral position\n",
    "#             keyboard.release('a')\n",
    "#             moving_left = False\n",
    "#             keyboard.release('d')\n",
    "#             moving_right = False\n",
    "        \n",
    "        \n",
    "        # Tilt Left / Right\n",
    "        if math.degrees(calib_roll) > thresh: # Head is tilted right\n",
    "            keyboard.release('a')\n",
    "            moving_left = False\n",
    "            if not moving_right:\n",
    "                keyboard.press('d')\n",
    "                moving_right = True\n",
    "        elif math.degrees(calib_roll) < -thresh: # Head is tilted left\n",
    "            keyboard.release('d')\n",
    "            moving_right = False\n",
    "            if not moving_left:\n",
    "                keyboard.press('a')\n",
    "                moving_left = True\n",
    "        else: # Head is in neutral position\n",
    "            keyboard.release('a')\n",
    "            moving_left = False\n",
    "            keyboard.release('d')\n",
    "            moving_right = False\n",
    "        \n",
    "        \n",
    "        # Up / Down\n",
    "        if math.degrees(calib_pitch) > thresh:\n",
    "            keyboard.release('s')\n",
    "            moving_up = False\n",
    "            if not moving_down:\n",
    "                keyboard.press('w')\n",
    "                moving_down = True\n",
    "        elif math.degrees(calib_pitch) < -thresh:\n",
    "            keyboard.release('w')\n",
    "            moving_down = False\n",
    "            if not moving_up:\n",
    "                keyboard.press('s')\n",
    "                moving_up = True\n",
    "        else: # Head is in neutral position\n",
    "            keyboard.release('w')\n",
    "            moving_down = False\n",
    "            keyboard.release('s')\n",
    "            moving_up = False\n",
    "    \n",
    "def calibrate_yaw_pitch_roll():\n",
    "    # Get access to global rest pos variables (I don't like python..)\n",
    "    # then set them to the current yaw, pitch, and roll of the user's head.\n",
    "    global yaw\n",
    "    global pitch\n",
    "    global roll\n",
    "    global rest_yaw\n",
    "    global rest_pitch\n",
    "    global rest_roll\n",
    "    rest_yaw = yaw\n",
    "    rest_pitch = pitch\n",
    "    rest_roll = roll\n",
    "    \n",
    "    # Print results\n",
    "    print(\"resting yaw is: \" + str(rest_yaw))\n",
    "    print(\"resting pitch is: \" + str(rest_pitch))\n",
    "    print(\"resting roll is: \" + str(rest_roll))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54373a91",
   "metadata": {},
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54a8a26d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Calibration -----\n",
      "Please look straight ahead at your screen, then press ENTER when comfortable\n",
      "resting yaw is: -0.014276866983158571\n",
      "resting pitch is: -0.3192686346271227\n",
      "resting roll is: 0.08348178980813038\n",
      "remapping paused set to: False\n"
     ]
    }
   ],
   "source": [
    "#!! import mediapipe as mp\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "    \n",
    "\n",
    "# Create a face landmarker instance with the live stream mode:\n",
    "def print_result(result: FaceLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    \n",
    "    # If any landmarks have been detected..\n",
    "    if result.face_landmarks:\n",
    "        \n",
    "        # Get the matrix from face landmarker\n",
    "        transf_matrix = result.facial_transformation_matrixes[0]\n",
    "        update_yaw_pitch_roll(transf_matrix)   \n",
    "    \n",
    "\n",
    "options = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "    result_callback=print_result,\n",
    "    output_facial_transformation_matrixes=True, ## TRY CHANGING THIS\n",
    "    output_face_blendshapes=False) ## TRY CHANGING THIS\n",
    "\n",
    "with FaceLandmarker.create_from_options(options) as landmarker:\n",
    "    # The landmarker is initialized. Use it here.\n",
    "    # Use OpenCVâ€™s VideoCapture to start capturing from the webcam.\n",
    "    video = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Initialise the frame timestamp (MAKE THIS IN ms?)\n",
    "    frame_timestamp = 0\n",
    "    \n",
    "    # Tell the user to calibrate\n",
    "    print(\"---- Calibration -----\")\n",
    "    print(\"Please look straight ahead at your screen, then press ENTER when comfortable\")\n",
    "    \n",
    "    # Create a loop to read the latest frame from the camera using VideoCapture#read()\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        # Convert the frame received from OpenCV to a MediaPipe Image object.\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "        \n",
    "        # Send live image data to perform face landmarking.\n",
    "        # The results are accessible via the `result_callback` provided in\n",
    "        # the `PoseLandmarkerOptions` object.\n",
    "        # The pose landmarker must be created with the live stream mode.\n",
    "        landmarker.detect_async(mp_image, frame_timestamp)\n",
    "        \n",
    "        # Increment the timestamp\n",
    "        frame_timestamp += 1\n",
    "        \n",
    "        # Draw the output\n",
    "        cv2.imshow('window', frame)\n",
    "        \n",
    "        # Listen for keyboard input\n",
    "        keyPressed = cv2.waitKey(5)\n",
    "        if keyPressed == ord('q'): # 'q': Break out of loop and exit program\n",
    "            break\n",
    "            \n",
    "        elif keyPressed == 13: # 'Enter': Calibrate yaw+pitch+roll\n",
    "            calibrate_yaw_pitch_roll()\n",
    "            \n",
    "        elif keyPressed == ord('0'): # '0': Toggle the the remapping\n",
    "            global remapping_paused\n",
    "            remapping_paused = not remapping_paused\n",
    "            print(\"remapping paused set to: {}\".format(remapping_paused))\n",
    "\n",
    "# Clean up\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb84630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-34 + (-10 * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5483877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-34 - -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d3e1a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-44"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-34 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5e5c447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-44"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-34 + (10 * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aaca17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
