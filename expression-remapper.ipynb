{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07df2a3a",
   "metadata": {},
   "source": [
    "# Expression remapper\n",
    "\n",
    "This notebook is a simple app that allows users to map different facial expressions and motions to keyboard inputs. I aim to use this to play a video game like Dark Souls as a test.\n",
    "\n",
    "Using MediaPipe, and following their [face landmark detection guide](https://developers.google.com/mediapipe/solutions/vision/face_landmarker/python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d845913",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658a179",
   "metadata": {},
   "source": [
    "#### Mediapipe\n",
    "Using for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a21808",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe\n",
    "# opencv as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ea24d",
   "metadata": {},
   "source": [
    "### Pynput\n",
    "Allows us to emulate keyboard inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d312bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynput\n",
      "  Downloading pynput-1.7.6-py2.py3-none-any.whl (89 kB)\n",
      "     ---------------------------------------- 0.0/89.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 89.2/89.2 kB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\newco\\anaconda3\\envs\\ml-creative-practice\\lib\\site-packages (from pynput) (1.16.0)\n",
      "Installing collected packages: pynput\n",
      "Successfully installed pynput-1.7.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pynput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e2a31",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5071e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mediapipe for face landmark detection\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# OpenCV for drawing utilities and webcam input\n",
    "import cv2\n",
    "\n",
    "# Generally useful for math\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Pynput for simulating keyboard inputs\n",
    "from pynput.keyboard import Key, Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d69400",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8bd572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/face_landmarker.task'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754a27c",
   "metadata": {},
   "source": [
    "## Utility functions for extracting head orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b69d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!! import math\n",
    "\n",
    "# Toggles whether the remapping is currently active. If paused, no keypresses will be simulated.\n",
    "remapping_paused = True\n",
    "\n",
    "# State variables\n",
    "keyboard = Controller()\n",
    "moving_up = False\n",
    "moving_down = False\n",
    "moving_left = False\n",
    "moving_right = False\n",
    "\n",
    "# Real yaw pitch and roll\n",
    "yaw = 0.0 # Rotate left/right\n",
    "pitch = 0.0 # Tilt up/down\n",
    "roll = 0.0 # Tilt left/right\n",
    "\n",
    "# Calibrated yaw pitch and roll values\n",
    "calib_yaw = 0\n",
    "calib_pitch = 0\n",
    "calib_roll = 0\n",
    "\n",
    "# The rest positions, used to calculate the calibrated values\n",
    "rest_yaw = 0.0\n",
    "rest_pitch = 0.0\n",
    "rest_roll = 0.0\n",
    "\n",
    "# Extract the yaw, pitch, and roll of the head from the facial transformation matrix\n",
    "# (yaw, pitch, and roll are easier for me to work with than a matrix)\n",
    "def update_yaw_pitch_roll(mtrix):\n",
    "    # Get access to the global variables\n",
    "    global yaw\n",
    "    global pitch\n",
    "    global roll\n",
    "\n",
    "    # Calculate the yaw pitch and roll from the transformation matrix (conversion)\n",
    "    if mtrix[0][0] == 1.0:\n",
    "        yaw = math.atan2(mtrix[0][2], mtrix[2][3])\n",
    "        pitch = 0\n",
    "        roll = 0\n",
    "\n",
    "    elif mtrix[0][0] == -1.0:\n",
    "        yaw = math.atan2(mtrix[0][0], mtrix[2][3])\n",
    "        pitch = 0\n",
    "        roll = 0\n",
    "\n",
    "    else:\n",
    "        yaw = math.atan2(-mtrix[2][0], mtrix[0][0])\n",
    "        pitch = math.atan2(-mtrix[1][2], mtrix[1][1])\n",
    "        roll = math.asin(mtrix[1][0])\n",
    "\n",
    "    # Calculate the CALIBRATED yaw pitch roll values\n",
    "    global calib_yaw\n",
    "    global calib_pitch\n",
    "    global calib_roll\n",
    "    calib_yaw = yaw - rest_yaw\n",
    "    calib_pitch = pitch - rest_pitch\n",
    "    calib_roll = roll - rest_roll\n",
    "\n",
    "    # Simulate key presses based on the head's orientation\n",
    "    if not remapping_paused:\n",
    "        global moving_left\n",
    "        global moving_right\n",
    "        global moving_up\n",
    "        global moving_down\n",
    "        \n",
    "        #print(math.degrees(calib_pitch))\n",
    "        thresh = 5.0\n",
    "#         # Look Left / Right\n",
    "#         if math.degrees(calib_yaw) > thresh: # Head is facing left\n",
    "#             keyboard.release('d')\n",
    "#             moving_right = False\n",
    "#             if not moving_left:\n",
    "#                 keyboard.press('a')\n",
    "#                 moving_left = True\n",
    "#         elif math.degrees(calib_yaw) < -thresh: # Head is facing right\n",
    "#             keyboard.release('a')\n",
    "#             moving_left = False\n",
    "#             if not moving_right:\n",
    "#                 keyboard.press('d')\n",
    "#                 moving_right = True\n",
    "#         else: # Head is in neutral position\n",
    "#             keyboard.release('a')\n",
    "#             moving_left = False\n",
    "#             keyboard.release('d')\n",
    "#             moving_right = False\n",
    "        \n",
    "        \n",
    "        # Tilt Left / Right\n",
    "        if math.degrees(calib_roll) > thresh: # Head is tilted right\n",
    "            keyboard.release('a')\n",
    "            moving_left = False\n",
    "            if not moving_right:\n",
    "                keyboard.press('d')\n",
    "                moving_right = True\n",
    "        elif math.degrees(calib_roll) < -thresh: # Head is tilted left\n",
    "            keyboard.release('d')\n",
    "            moving_right = False\n",
    "            if not moving_left:\n",
    "                keyboard.press('a')\n",
    "                moving_left = True\n",
    "        else: # Head is in neutral position\n",
    "            keyboard.release('a')\n",
    "            moving_left = False\n",
    "            keyboard.release('d')\n",
    "            moving_right = False\n",
    "        \n",
    "        \n",
    "        # Look Up / Down\n",
    "        if math.degrees(calib_pitch) > thresh:\n",
    "            keyboard.release('s')\n",
    "            moving_up = False\n",
    "            if not moving_down:\n",
    "                keyboard.press('w')\n",
    "                moving_down = True\n",
    "        elif math.degrees(calib_pitch) < -thresh:\n",
    "            keyboard.release('w')\n",
    "            moving_down = False\n",
    "            if not moving_up:\n",
    "                keyboard.press('s')\n",
    "                moving_up = True\n",
    "        else: # Head is in neutral position\n",
    "            keyboard.release('w')\n",
    "            moving_down = False\n",
    "            keyboard.release('s')\n",
    "            moving_up = False\n",
    "    \n",
    "def calibrate_yaw_pitch_roll():\n",
    "    # Get access to global rest pos variables (I don't like python..)\n",
    "    # then set them to the current yaw, pitch, and roll of the user's head.\n",
    "    global yaw\n",
    "    global pitch\n",
    "    global roll\n",
    "    global rest_yaw\n",
    "    global rest_pitch\n",
    "    global rest_roll\n",
    "    rest_yaw = yaw\n",
    "    rest_pitch = pitch\n",
    "    rest_roll = roll\n",
    "    \n",
    "    # Print results\n",
    "    print(\"resting yaw is: \" + str(rest_yaw))\n",
    "    print(\"resting pitch is: \" + str(rest_pitch))\n",
    "    print(\"resting roll is: \" + str(rest_roll))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b7669",
   "metadata": {},
   "source": [
    "## Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03731dbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Calibration -----\n",
      "\n",
      "Please look straight ahead at your screen, then press ENTER when comfortable\n",
      "This will calibrate your 'neutral' position.\n",
      "When you are ready to start playing, press '0' and keyboard inputs will begin to be simulated as you move your head.\n",
      "\n",
      "To stop, press '0' again.\n",
      "\n",
      "\n",
      "---- How to use -----\n",
      "\n",
      "Tilt your head left/right (roll) to simulate pressing 'a' and 'd' respectively\n",
      "\n",
      "Tilt your head forward/back (pitch) to simulate pressing the 'w' and 's' keys.\n",
      "\n",
      "You can refer to this image for a reference of what 'pitch' and 'roll' mean: \n",
      "https://miro.medium.com/v2/resize:fit:604/format:webp/0*3aYfZkNKTeobv07d.png\n",
      "resting yaw is: -0.017907986342970576\n",
      "resting pitch is: -0.32248256654187685\n",
      "resting roll is: 0.10059089208864247\n"
     ]
    }
   ],
   "source": [
    "#!! import mediapipe as mp\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "    \n",
    "\n",
    "# Create a face landmarker instance with the live stream mode:\n",
    "def print_result(result: FaceLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    \n",
    "    # If any landmarks have been detected..\n",
    "    if result.face_landmarks:\n",
    "        \n",
    "        # Get the matrix from face landmarker\n",
    "        transf_matrix = result.facial_transformation_matrixes[0]\n",
    "        update_yaw_pitch_roll(transf_matrix)   \n",
    "    \n",
    "    \n",
    "options = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "    result_callback=print_result,\n",
    "    output_facial_transformation_matrixes=True, ## TRY CHANGING THIS\n",
    "    output_face_blendshapes=False) ## TRY CHANGING THIS\n",
    "\n",
    "with FaceLandmarker.create_from_options(options) as landmarker:\n",
    "    # The landmarker is initialized. Use it here.\n",
    "    # Use OpenCV’s VideoCapture to start capturing from the webcam.\n",
    "    video = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Initialise the frame timestamp (MAKE THIS IN ms?)\n",
    "    frame_timestamp = 0\n",
    "    prev_frame_time = 0\n",
    "    new_frame_time = 0\n",
    "    \n",
    "    # Print user instructions\n",
    "    print(\"---- Calibration -----\\n\")\n",
    "    print(\"Please look straight ahead at your screen, then press ENTER when comfortable\\nThis will calibrate your 'neutral' position.\")\n",
    "    print(\"When you are ready to start playing, press '0' and keyboard inputs will begin to be simulated as you move your head.\\n\\nTo stop, press '0' again.\\n\\n\")\n",
    "    print(\"---- How to use -----\\n\")\n",
    "    print(\"Tilt your head left/right (roll) to simulate pressing 'a' and 'd' respectively\\n\")\n",
    "    print(\"Tilt your head forward/back (pitch) to simulate pressing the 'w' and 's' keys.\\n\")\n",
    "    print(\"You can refer to this image for a reference of what 'pitch' and 'roll' mean: \\nhttps://miro.medium.com/v2/resize:fit:604/format:webp/0*3aYfZkNKTeobv07d.png\")\n",
    "    \n",
    "    # Create a loop to read the latest frame from the camera using VideoCapture#read()\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        # break if there's no video input\n",
    "        if not ret: \n",
    "            break\n",
    "        \n",
    "        # Record the current time this frame\n",
    "        new_frame_time = time.time()\n",
    "        \n",
    "        # Convert the frame received from OpenCV to a MediaPipe Image object.\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "        \n",
    "        # To improve performance, apparently\n",
    "        frame.flags.writeable = False\n",
    "        \n",
    "        # Send live image data to perform face landmarking.\n",
    "        # The results are accessible via the `result_callback` provided in\n",
    "        # the `PoseLandmarkerOptions` object.\n",
    "        # The pose landmarker must be created with the live stream mode.\n",
    "        landmarker.detect_async(mp_image, frame_timestamp)\n",
    "        \n",
    "        # To improve performance, apparently\n",
    "        frame.flags.writeable = True\n",
    "        \n",
    "        # Increment the timestamp\n",
    "        frame_timestamp += 1\n",
    "        \n",
    "        # Calculate and display FPS\n",
    "        fps = 1/(new_frame_time-prev_frame_time) \n",
    "        prev_frame_time = new_frame_time \n",
    "\n",
    "        fps = int(fps) # convert fps to int (from float) \n",
    "        fps = str(fps) # convert fps to str (from int) so it can be displayed\n",
    "\n",
    "        # drawing FPS counter to the frame\n",
    "        cv2.putText(frame, fps, (7, 70), cv2.FONT_HERSHEY_SIMPLEX, 3, (100, 255, 0), 3, cv2.LINE_AA) \n",
    "    \n",
    "        # Draw the output\n",
    "        cv2.imshow('window', frame)\n",
    "        \n",
    "        # Listen for keyboard input\n",
    "        keyPressed = cv2.waitKey(5)\n",
    "        if keyPressed == ord('q'): # 'q': Break out of loop and exit program\n",
    "            break\n",
    "            \n",
    "        elif keyPressed == 13: # 'Enter': Calibrate yaw+pitch+roll\n",
    "            calibrate_yaw_pitch_roll()\n",
    "            \n",
    "        elif keyPressed == ord('0'): # '0': Toggle the the remapping\n",
    "            global remapping_paused\n",
    "            remapping_paused = not remapping_paused\n",
    "            print(\"remapping paused set to: {}\".format(remapping_paused))\n",
    "\n",
    "# Clean up\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
